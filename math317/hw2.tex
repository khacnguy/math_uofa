\documentclass[11pt]{article}
    \title{\textbf{Math 217 Homework I}}
    \author{Khac Nguyen Nguyen}
    \date{}
    
    \addtolength{\topmargin}{-3cm}
    \addtolength{\textheight}{3cm}
    
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{pgfplots}
\usepackage{xfrac}
\usepgfplotslibrary{polar}
\usepgflibrary{shapes.geometric}
\usetikzlibrary{calc}
\pgfplotsset{compat = newest}
\pgfplotsset{my style/.append style = {axis x line = middle, axis y line = middle, xlabel={$x$}, ylabel={$y$}, axis equal}}
\begin{document}
\section*{1.}
Consider the function
\[
    g: \mathbb{R}^2 \to \mathbb{R}, \indent (x,y) \to f(x,y)-1
\]
Then consider the set $U$ satisfies $f(x,y) = 1 \iff g(x,y)=0$. \\
Let $(x_0,y_0) = (0,1)$. We have that 
\[
    \det 
    \begin{bmatrix} 
        \frac{\partial g}{\partial y} (x_0,y_0)
    \end{bmatrix} 
    = 2 \ne 0   
\]
Therefore, there exsits a neighborhood $V$ and hence a $\epsilon >0$ and a function $\phi$ such that 
$(-\epsilon, \epsilon) \subset V \subset \mathbb{R}$ of $x_0$, 
$\phi: (-\epsilon, \epsilon) \to \mathbb{R}$ with $\phi(0) = 1$ and $f(x,y) = 1$ for all 
$x\in \mathbb{R}$ with $|x| < \epsilon$ and 
\[
    \phi'(x) = -\left(\frac{\partial f}{\partial y}(x,\phi(x))\right)^{-1} \cdot \frac{\partial f}{\partial x}(x,\phi(x)) = -\left( 2 \phi(x)\right)^{-1} \cdot 2x = -\frac{x}{\phi(x)}    
\]
for $x \in (-\epsilon ,\epsilon )$
\pagebreak
\section*{2.}
\subsection*{a.}
Consider the funciton 
\[
    F: \mathbb{R}^4 \to \mathbb{R}, \indent (x_1,y_1,x_2,y_2) \to (x_1-x_2)^2 + (y_1-y_2)^2
\]
and the
\[
    \phi: \mathbb{R}^4 \to \mathbb{R}^2, \indent (x_1,y_1,x_2,y_2) \to 
    \begin{pmatrix}
        f(x_1,y_1) \\
        g(x_2,y_2)
    \end{pmatrix}    
\]
We know that 
\[
    J_\phi(\alpha,\beta,\xi,\eta) = 
    \begin{bmatrix}
        f_{x}(\alpha,\beta) & f_{y}(\alpha,\beta) & 0 & 0 \\
        0 & 0 & g_{x}(\xi,\eta) & g_{y}(\xi,\eta)
    \end{bmatrix}    
\]
If rank$J_f(x_0) = 0$, it is trivial that we get the desired results as 
\[
    f_{x}(\alpha,\beta) = f_{y}(\alpha,\beta) = g_{x}(\xi,\eta) = g_{y}(\xi,\eta) = 0    
\]
If rank$J_f(x_0) = 1$, then WLOG assume $f_{x}(\alpha,\beta) = f_{y}(\alpha,\beta) = 0$ and 
$(\nabla g)(\xi,\eta) \ne 0$. Then 
\[
    f_y(\alpha,\beta)(\alpha-\xi) = f_x(\alpha,\beta)(\beta-\eta)
\]
and consider the functions
\[
    F': \mathbb{R}^2 \to \mathbb{R}, \indent (x_2,y_2) \to (x_2 - \alpha)^2 + (y_2- \beta)^2  
\]
\[
    \phi_g: \mathbb{R}^2 \to \mathbb{R}, \indent (x,y) \to g(x,y)
\]
We know that $F'$ attains an extremum at $(\xi,\eta)$ under the constraint function 
$\phi_g(x)=0$. Therefore, there exists $\lambda \in \mathbb{R}$ such that 
\[
    \nabla F'(\xi,\eta) = \lambda (\nabla \phi_g)(\xi,\eta)    
\]
\[
    (2\xi - 2 \alpha , 2\eta-2\beta) = \lambda (g_x(\xi,\eta), g_y(\xi,\eta))
\]
and therefore
\[
    g_y(\xi,\eta)(\alpha-\xi) = g_x(\xi,\eta)(\beta-\eta)
\]
If rank$J_f(x_0) = 2$, then there exists $\lambda_1, \lambda_2 \in \mathbb{R}$ such that 
\[
    (\nabla F)(\alpha,\beta, \xi,\eta) = \lambda_1 (\nabla \phi_1) (\alpha,\beta, \xi,\eta) + \lambda_2 (\nabla \phi_2) (\alpha,\beta, \xi,\eta)
\]
and hence
\[
    (2\alpha-2\xi, 2\beta-2\eta) = \lambda_1 (f_x(\alpha,\beta), f_y(\alpha,\beta))    
\]
and
\[
    (2\xi- 2\alpha, 2\eta-2\beta) = \lambda_2 (g_x(\xi,\eta), g_y(\xi,\eta))    
\] 
Therefore, we get the results
\[
    f_y(\alpha,\beta)(\alpha-\xi) = f_x(\alpha,\beta)(\beta-\eta)
\]
and
\[
    g_y(\xi,\eta)(\alpha-\xi) = g_x(\xi,\eta)(\beta-\eta)
\]
\subsection*{b.}
Consider two smooth curves $f(x,y) = x + y - 2 = 0$ and $g(x,y) = x^2+2y^2-1=0$.
We have that
\[
    f_x(x,y) = f_y(x,y) = 1, g_x(x,y) = 2x, g_y(x,y) = 4y    
\]
Then there is two points $(\alpha,\beta), (\xi,\eta)$ lying on the respective curves such that 
the distance between those two points is the minimum and hence is the distance between those curves. \\
Substitute what we know into the results obtained from part a, we have that
\[
    \alpha-\xi = \beta - \eta     
\] 
and 
\[
    4\eta (\alpha-\xi) = 2\xi (\beta-\eta) = 2\xi(\alpha-\xi)    
\]
Therefore, $\xi = 2\eta$. Substitute that into $g(x,y) = 0$, we have
\[
    (2\eta)^2 + 2\eta^2 - 1 = 0 \implies \eta = \frac{1}{\sqrt{6}} \text{ or } -\frac{1}{\sqrt{6}}
\]
We have that 
\[  
    \alpha - 2\eta = \beta - \eta \implies \alpha = \beta + \eta
\]
Subtracting two equations together
\[
    \begin{cases}
        \alpha + \beta = 2 \\
        \alpha - \beta = \eta 
    \end{cases}    
\]
We get that $\beta = \cfrac{2-\eta}{2}$, and hence $\beta - \eta = \cfrac{2-3\eta}{2}$ 
The distance between $(\alpha,\beta)$ and $(\xi,\eta)$ is 
\[
    \sqrt{(\alpha- \xi)^2 + (\beta - \eta^2)} = \sqrt{2}|\beta-\eta| = \sqrt{2}\left|\frac{2-3\eta}{2}\right|
\]
Substitute the two cases of $\eta$ in, we get that 
the minimum distance is $\cfrac{2\sqrt{2} - \sqrt{3}}{6}$ when $\eta = \cfrac{1}{\sqrt{6}}$ 
and the maximum distance is $\cfrac{2\sqrt{2} + \sqrt{3}}{6}$ when $\eta = -\cfrac{1}{\sqrt{6}}$

\pagebreak
\section*{3.}
As $K$ is compact and $f$ is continuous, $f$ attains both a minimum and a maximum on $K$. First we consider the interior of $K$.
We have
\[
    \nabla f(x,y,z) = (2x-2,2y,2z+2) = 0 \iff (x,y,z) = (1,0,-1)
\]
Since 
\[
    (\text{Hess} f)(1,0,-1) = 
    \begin{bmatrix}
        2 & 0 & 0 \\
        0 & 1 & 0 \\
        0 & 0 & 2 
    \end{bmatrix}    
\]
the Hessian is positive definite and hence $f$ attains its minimum at $(1,0,-1)$ with the value of $f(1,0,-1) = -1$ Therefore, $f$ attains its maximum on 
$\partial K$. Let 
\[
    \phi: \mathbb{R}^3 \to \mathbb{R}, \indent (x,y,z) \to x^2 + y^2 + z^2 - 9    
\]
so that $\partial K = \{(x,y,z)\in \mathbb{R}^3: \phi(x,y,z) = 0\}$. We then have that 
\[
    2y = 2\lambda y \implies \lambda = 1 \text{ or } y=0
\]
In case $\lambda = 1$, we have that 
\[
    2x-2 = 2\lambda x = 2x  
\]
and hence there is no solution. \\
In case $y=0$, as $2x-2=2\lambda x$ and $2z+2 = 2\lambda z$, $x\ne 0$ and $z\ne 0$. Therefore, we have that
\[
    \frac{2x-2}{2x} = \lambda = \frac{2z+2}{2z} \implies x = -z    
\]
Therefore, 
\[
    x^2+y^2+z^2=9 \implies (x,z) = \left(\frac{3\sqrt{2}}{2},-\frac{3\sqrt{2}}{2}\right) \text{ or } (x,z) = \left(-\frac{3\sqrt{2}}{2},\frac{3\sqrt{2}}{2}\right)    
\]
To sum everything up 
\[
    f(2,1,-2) = 2, f\left(\frac{3\sqrt{2}}{2},0,-\frac{3\sqrt{2}}{2}\right) = 1.515, f\left(-\frac{3\sqrt{2}}{2},0,\frac{3\sqrt{2}}{2}\right) = 18.485 
\]
and hence $f$ attains its maximum at $\left(\frac{3\sqrt{2}}{2},0,-\frac{3\sqrt{2}}{2}\right)$ with the value of 18.485
and its minimum at $(1,0,-1)$ with the value of -1.
\pagebreak
\section*{4.}
\subsection*{a.}
Consider the function
\[
    \phi: \mathbb{R}^2 \to \mathbb{R}, \indent (x,y) \to 1-xy    
\]
then at the point $(x_0, y_0)$ where $f$ attains its extremum, we have
\begin{equation*}
    \begin{aligned}
        &\frac{\partial f}{\partial x}(x_0,y_0) = \frac{\partial f}{\partial y} (x_0,y_0) \cdot \left( \frac{\partial \phi}{\partial y}(x_0,y_0) \right)^{-1} \cdot \frac{\partial f}{ \partial x} (x_0,y_0) \\  
        \implies & x_0^{p-1} = y_0^{q-1} \cdot \frac{1}{-x_0} \cdot (-y_0) \\ 
        \implies & x_0^p = y_0^q \\
        \implies & x_0^{p+q} = 1 \\
        \implies & x_0 = 1 \text{ (p+q} \ne 0) \\
        \implies & y_0 = 1
    \end{aligned}
\end{equation*}
Therefore, the minimum is 
\[
    f(1,1) = \frac{1}{p}+ \frac{1}{q} = 1
\]
as it cannot be the maximum because $\lim_{x \to \infty} f(x,\frac{1}{x}) = \infty $
\subsection*{b.}
Changing $\phi$ 
\[
    \phi: \mathbb{R}^2 \to \mathbb{R}, \indent (x,y) \to ab-xy    
\]

If $(x_0,y_0)$ is where $f$ attains its extremum, then applying the same process, we have
\begin{equation*}
    \begin{aligned}
        &x_0^p = y_0^q
        \implies & (ab)^p = y_0^{p+q} = (y_0^q)^p
        \implies & ab = y_0^q
    \end{aligned}
\end{equation*}
Hence, $f$ attains its minimum at $(x_0,y_0)$ and 
\[
    f(x_0,y_0) =  \frac{x_0^p}{p} + \frac{y_0^q}{q} = y_0^q\left(\frac{1}{p} + \frac{1}{q}\right) = ab
\]
as it cannot be the maximim because $\lim_{x \to \infty} f(x,\frac{ab}{x}) = \infty $
and hence we have that 
\[
    f(a,b) = \frac{a^p}{p}+\frac{b^q}{q} \ge ab    
\]
\subsection*{c.}
Let $x_k = \cfrac{a_k}{\left(\sum_{j=1}^n a_j^p \right)^{1/p}}, y_k = \cfrac{b_k}{\left(\sum_{j=1}^n b_j^q \right)^{1/q}}$.
We have that 
\begin{equation*}
    \begin{aligned}
        \sum_{k=1}^n x_ky_k &= \sum_{k=1}^n \frac{a_k b_k}{\left(\sum_{j=1}^n a_j^p \right)^{1/p} \left(\sum_{j=1}^n b_j^q \right)^{1/q}} \\
        \le & \sum_{k=1}^n 
        \frac{a_k^p}{p\left(\sum_{j=1}^n a_k^p \right)} 
        + \frac{b_k^q}{q\left(\sum_{j=1}^n b_j^q \right)}  \\
        =& \frac{\sum_{k=1}^n a_k^p}{p\left(\sum_{j=1}^n a_j^p \right)} 
        + \frac{\sum_{k=1}^n b_k^p}{q\left(\sum_{j=1}^n b_j^q \right)} \\
        =& \frac{1}{p} + \frac{1}{q} \\
        =& 1
    \end{aligned}
\end{equation*}
Multiplying both sides of the inequality by $\left(\sum_{k=1}^n a_k^p \right)^{1/p}\left(\sum_{k=1}^n b_k^q \right)^{1/q}$, we get the results 
\[
    \sum_{k=1}^n a_kb_k \le \left(\sum_{k=1}^n a_k^p \right)^{1/p}\left(\sum_{k=1}^n b_k^q \right)^{1/q}    
\]
\subsection*{d.}
Since $p\ge 1$, there exists a $q \in \mathbb{R}$ such that $\frac{1}{p}+ \frac{1}{q} = 1$. Therefore, 
\begin{equation*}
    \begin{aligned}
        \sum_{k=1}^n |a_k + b_k|^p 
        &= \sum_{k=1}^n |a_k + b_k| \cdot |a_k+b_k|^{p-1} \\
        &\le \left(\sum_{k=1}^n |a_k + b_k|^p \right)^{1/p} \cdot 
        \left( \sum_{k=1}^n (|a_k + b_k|^{p-1} )^q \right)^{1/q} \\
        &\le \left(\sum_{k=1}^n |a_k|^p \right)^{1/p} \cdot
        \left( \sum_{k=1}^n (|a_k + b_k|^{p-1} )^q \right)^{1/q} \\
        & +\left(\sum_{k=1}^n |b_k|^p \right)^{1/p} \cdot
        \left( \sum_{k=1}^n (|a_k + b_k|^{p-1} )^q \right)^{1/q} \\
        &= \left(\left(\sum_{k=1}^n |a_k|^p \right)^{1/p} 
        + \left(\sum_{k=1}^n |b_k|^p \right)^{1/p} \right)
        \left( \sum_{k=1}^n |a_k + b_k|^p \right)^{1/q} \\
    \end{aligned}
\end{equation*}
\pagebreak
Dividing both sides of the inequality by $\left( \sum_{k=1}^n |a_k + b_k|^p \right)^{1/q}$, we get the desired results as $1-\frac{1}{q}=\frac{1}{p}$

\[
    \left(\sum_{k=1}^n |a_k+b_k|^p \right)^{1/p} \le \left(\sum_{k=1}^n |a_k|^p \right)^{1/p} 
    + \left(\sum_{k=1}^n |b_k|^p \right)^{1/p}
\]
\pagebreak
\section*{5.}
\begin{proof}
Consider the function $F$:
\[
    F: U \times f_1(U) \to \mathbb{R}, \indent (x,y,t) \to f_1(x,y) - t    
\]
Then we have that
\[
    \frac{\partial F}{\partial x}(x_0,y_0,f_1(x_0,y_0)) = \frac{\partial f_1}{\partial x}(x_0,y_0) \ne 0   
\]
and 
\[
    F(x_0,y_0,f_1(x_0,y_0)) = 0    
\]
Therefore, there exists neighborhoods $V \subset \mathbb{R}^2$ of $(y_0,f_1(x_0,y_0))$ and
$W \subset \mathbb{R}$ of $x_0$ such that $W \times V \subset U \times \mathbb{R}$ and 
a unique $\phi \in \mathcal{C}^1(V, \mathbb{R})$ such that for all $(x,y,t) \in U \times f_1(U):$
\[
    x = \phi(y,t) \iff f_1(x,y) = t 
\]
Thus, we have that
\[
    f_1(\phi(y,t),y) = t
\]
and hence, taking the derivative with respect to $y$, we get
\[
    f_{1_x}(\phi(y,t),y) \cdot \phi_y(y,t) + f_{1_y}(\phi(y,t),y) = 0
\]
\[
    \implies \phi_y(y,t) = -\frac{f_{1_y}(\phi(y,t),y)}{f_{1_x}(\phi(y,t),y)} = -\frac{f_{2_y}(\phi(y,t),y)}{f_{2_x}(\phi(y,t),y)} 
\]
as rank $J_f(x,y) = 1$ for all $(x,y) \in U$.
Now consider the function:
\[
    \psi: V \to f_2(U), \indent (y,t) \to f_2(\phi(y,t),y)
\]
We can see that $\psi$ is not dependent on $y$ as 
\[
    \psi_y = f_{2_x}(\phi(y,t),y) \cdot \phi_y(y,t) + f_{2_y}(\phi(y,t),y) = 0
\]
It is possible then to rewrite $\psi$ as 
\[
    \psi: V_t \to f_2(U), \indent t \to f_2(\phi(y,t),y)    
\]
Let $(x, y)$ be an arbitary point in $W \times V_t$ 
then we can find a $t$ such that $f_1(x,y) = t \iff x = \phi(y,t)$ and therefore
\[
    f_2(x,y) = f_2(\phi(y,t),y) = \psi(t) = \psi(f_1(x,y))    
\]
which finishes the proof.
\end{proof}
\pagebreak
\section*{6.}
\subsection*{1.}
If $f_xg_y - f_yg_x$ vanishes on a neighborhood of $(x_0,y_0)$ which we denote $U$, 
then in the case where $f_x = g_y = f_y = f_x = 0$, it is trivial that the function 
\[
    \phi: U \to \mathbb{R}, \indent (x,y) \to f(x_0,y_0)
\]
satisfies the condition 
In the other case, if $\frac{\partial f}{\partial x}(x_0,y_0) \ne 0$ then define
\[
    F: U \to \mathbb{R}^2, \indent (x,y) \to (f(x,y), g(x,y))    
\]
such that rank$J_f = 1$ as $f_xg_y - f_yg_x = 0$ and 
$\frac{\partial F_1}{\partial x}(x_0,y_0) = \frac{\partial f}{\partial x}(x_0,y_0) \ne 0$.
Hence, there is a function $\phi \in \mathcal{C}^1(\mathbb{R}, \mathbb{R})$ such that $g(x,y) = \phi(f(x,y))$. \\
If $\frac{\partial g}{\partial x}(x_0,y_0) \ne 0$ or $\frac{\partial f}{\partial y}(x_0,y_0) \ne 0$ or $\frac{\partial g}{\partial y}(x_0,y_0) \ne 0$,
then applying the same process we have that there is a funciton $\phi \in \mathcal{C}^1(\mathbb{R},\mathbb{R})$ such that 
$f(x,y) = \phi(g(x,y))$ or $g(x,y) = \phi(f(x,y,))$. \\
\subsection*{2.}
If there is a function $\phi \in \mathcal{C}^1(\mathbb{R}, \mathbb{R})$ such that $f(x,y) = \phi(g(x,y))$.
Then we have that 
\[
    J_f(x,y) = J_{\phi \circ g}(x,y) = J_\phi(g(x,y)) \cdot J_g(x,y)    
\]
and hence 
\[
    f_x(x,y) = \frac{\phi(g(x,y)}{\partial x} = \phi'(g(x,y)) \cdot g_x(x,y)   
\]
\[
    f_y(x,y) = \frac{\phi(g(x,y)}{\partial y} = \phi'(g(x,y)) \cdot g_y(x,y)   
\]
As a result, we can get that $\frac{f_x}{g_x} = \frac{f_y}{g_y}$ and therefore
\[
    f_xg_y - f_yg_x = 0    
\]
\end{document}