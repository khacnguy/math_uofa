{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "Ee12uTT4VqJI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import timeit\n",
        "\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import warnings\n",
        "#warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "-skjpFYuWCJT"
      },
      "outputs": [],
      "source": [
        "class logistic_regression(object):\n",
        "    def __init__(self, features, obs, d):\n",
        "      self.x = features\n",
        "      self.y = obs\n",
        "      self.d = d\n",
        "\n",
        "    def logLoss(self, weights):\n",
        "      y_hat = self.sigmoid(self.x.dot(weights))\n",
        "      y_hat_inv = 1- y_hat\n",
        "      return - np.nansum(self.y * np.log(y_hat) + y_hat_inv* np.log(y_hat_inv))\n",
        "\n",
        "    def sigmoid(self, t):\n",
        "      return 1/(1+np.exp(-t))\n",
        "\n",
        "    def derivative(self, weights):\n",
        "      y_hat = self.sigmoid(self.x.dot(weights))\n",
        "      return -self.x.T.dot(self.y-y_hat)\n",
        "\n",
        "    def solve(self, show_result = False):\n",
        "      #seed just to make sure don't generate bad number afterwards (still under 10s in that case)\n",
        "      np.random.seed(4)\n",
        "      max = 0.015\n",
        "      min = -0.015\n",
        "      result = minimize(self.logLoss, min + (max-min)*np.random.rand(10), method='BFGS', jac=self.derivative)\n",
        "      if show_result:\n",
        "        print('Status : %s' % result['message'])\n",
        "        print('Total Evaluations: %d' % result['nfev'])\n",
        "      self.weights = result['x']\n",
        "      return self.weights\n",
        "\n",
        "    def predict(self, X, threshold):\n",
        "        y_predicted = self.sigmoid(np.dot(X, self.weights))\n",
        "        y_predicted_cls = [1 if i > threshold else 0 for i in y_predicted]\n",
        "        return np.array(y_predicted_cls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "k2GyaOlTWMJL"
      },
      "outputs": [],
      "source": [
        "#IMPORT DATA HERE\n",
        "x = np.load(\"feature.npy\")\n",
        "y = np.load(\"obs.npy\")\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.1, random_state=3)\n",
        "d = x.shape[1]\n",
        "\n",
        "predictor = logistic_regression(xtrain, ytrain, d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVugvqSxNZcv",
        "outputId": "69c23c72-873d-4fa3-85e5-637d6da05b69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7618093230000795\n",
            "[1.17668529 0.26183304 0.24005343 0.31594052 1.25534288 0.13334372\n",
            " 0.52273025 1.05709867 0.47065912 0.88363106]\n"
          ]
        }
      ],
      "source": [
        "#DO NOT CHANGE THIS CELL\n",
        "tic = timeit.default_timer()\n",
        "\n",
        "#Your solver goes here. Do not add any code here.\n",
        "theta = predictor.solve()\n",
        "\n",
        "toc = timeit.default_timer()\n",
        "\n",
        "\n",
        "print(toc - tic)\n",
        "print(theta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VemXB2Oi1WEs",
        "outputId": "38377a07-2fd4-4878-c840-9e6c055ecfd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BGFS classification accuracy: 0.99119\n",
            "GD classification accuracy: 0.99938\n",
            "division of the 2 weights from 2 methods:  [2.68262139 2.82689988 2.77191614 2.44134482 2.52657637 2.57213395\n",
            " 2.71050829 2.64885754 2.59654052 2.58731487]\n",
            "standard deviation of the division:  0.10985191276551118\n"
          ]
        }
      ],
      "source": [
        "class LogisticRegression2:\n",
        "    def __init__(self, x, y, learning_rate, iteration):\n",
        "        self.lr = learning_rate\n",
        "        self.iteration = iteration\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.N = self.x.shape[0]\n",
        "    def solve(self, show_message = False):\n",
        "        self.weights = np.zeros(self.x.shape[1])\n",
        "\n",
        "        # gradient descent\n",
        "        for _ in range(self.iteration):\n",
        "            y_predicted = self.sigmoid(np.dot(self.x, self.weights))\n",
        "\n",
        "            dw = np.dot(self.x.T, (y_predicted - self.y))/self.N\n",
        "            if sum(abs(dw)) < 0.5:\n",
        "              if show_message:\n",
        "                print(\"The weights has converged\")\n",
        "              break\n",
        "            # update parameters\n",
        "            self.weights -= self.lr * dw\n",
        "\n",
        "    def predict(self, X, threshold):\n",
        "        linear_model = np.dot(X, self.weights)\n",
        "        y_predicted = self.sigmoid(linear_model)\n",
        "        y_predicted_cls = [1 if i > threshold else 0 for i in y_predicted]\n",
        "        return np.array(y_predicted_cls)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "    return accuracy\n",
        "\n",
        "threshold = 0.5\n",
        "ytest = (ytest > threshold).astype('int')\n",
        "predictions = predictor.predict(xtest, threshold)\n",
        "print(\"BGFS classification accuracy:\", accuracy(ytest, predictions))\n",
        "predictor2 = LogisticRegression2(xtrain, ytrain, 0.1, 100)\n",
        "predictor2.solve()\n",
        "predictions2 = predictor2.predict(xtest, threshold)\n",
        "print(\"GD classification accuracy:\", accuracy(ytest, predictions2))\n",
        "division = predictor.weights/predictor2.weights\n",
        "print(\"division of the 2 weights from 2 methods: \", division)\n",
        "print(\"standard deviation of the division: \", np.std(division))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}